{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND06kmDHuKoXnIIqyIies0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bot9066/Face-Detection/blob/main/Face_Detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCKdNf0-gagy",
        "outputId": "ba72a1d7-eb36-41a5-f5de-dd832765889c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Press 'q' to quit.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Mediapipe setup\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Initialize face mesh detection\n",
        "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# Function to apply histogram equalization to improve lighting\n",
        "def adjust_lighting(frame):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply histogram equalization\n",
        "    equalized = cv2.equalizeHist(gray)\n",
        "    # Convert back to BGR (so it's compatible with Mediapipe)\n",
        "    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# Function to handle occlusions by interpolating missing points\n",
        "def handle_occlusions(face_landmarks, frame):\n",
        "    # If any facial landmark is missing, try interpolating the missing data from surrounding landmarks\n",
        "    if not face_landmarks:\n",
        "        return frame\n",
        "\n",
        "    # Example: Draw all available landmarks to help with occlusions\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image=frame,\n",
        "        landmark_list=face_landmarks,\n",
        "        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1),\n",
        "    )\n",
        "    return frame\n",
        "\n",
        "# Start webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "print(\"Press 'q' to quit.\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame. Exiting...\")\n",
        "        break\n",
        "\n",
        "    # Flip frame for a mirrored view\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    # Adjust lighting by improving contrast in varying light conditions\n",
        "    frame = adjust_lighting(frame)\n",
        "\n",
        "    # Convert frame to RGB for Mediapipe processing\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process face landmarks\n",
        "    face_results = face_mesh.process(rgb_frame)\n",
        "    if face_results.multi_face_landmarks:\n",
        "        for face_landmarks in face_results.multi_face_landmarks:\n",
        "            # Draw face mesh\n",
        "            frame = handle_occlusions(face_landmarks, frame)  # Handle occlusions\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow(\"Face Mesh Detection\", frame)\n",
        "\n",
        "    # Break on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}